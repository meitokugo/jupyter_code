{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the word list!\n",
      "Loaded the word vectors!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "wordsList = np.load('./imdb/wordsList.npy')\n",
    "print('Loaded the word list!')\n",
    "wordsList = wordsList.tolist() #Originally loaded as numpy array\n",
    "wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
    "wordVectors = np.load('./imdb/wordVectors.npy')\n",
    "print ('Loaded the word vectors!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n",
      "(400000, 50)\n"
     ]
    }
   ],
   "source": [
    "print(len(wordsList))\n",
    "print(wordVectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.93270004,  1.04209995, -0.78514999,  0.91033   ,  0.22711   ,\n",
       "       -0.62158   , -1.64929998,  0.07686   , -0.58679998,  0.058831  ,\n",
       "        0.35628   ,  0.68915999, -0.50598001,  0.70472997,  1.26639998,\n",
       "       -0.40031001, -0.020687  ,  0.80862999, -0.90565997, -0.074054  ,\n",
       "       -0.87674999, -0.62910002, -0.12684999,  0.11524   , -0.55685002,\n",
       "       -1.68260002, -0.26291001,  0.22632   ,  0.713     , -1.08280003,\n",
       "        2.12310004,  0.49869001,  0.066711  , -0.48225999, -0.17896999,\n",
       "        0.47699001,  0.16384   ,  0.16537   , -0.11506   , -0.15962   ,\n",
       "       -0.94926   , -0.42833   , -0.59456998,  1.35660005, -0.27506   ,\n",
       "        0.19918001, -0.36008   ,  0.55667001, -0.70314997,  0.17157   ], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseballIndex = wordsList.index('baseball')\n",
    "wordVectors[baseballIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "[    41    804 201534   1005     15   7446      5  13767      0      0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "maxSeqLength = 10 #Maximum length of sentence\n",
    "numDimensions = 300 #Dimensions for each word vector\n",
    "firstSentence = np.zeros((maxSeqLength), dtype='int32')\n",
    "firstSentence[0] = wordsList.index(\"i\")\n",
    "firstSentence[1] = wordsList.index(\"thought\")\n",
    "firstSentence[2] = wordsList.index(\"the\")\n",
    "firstSentence[3] = wordsList.index(\"movie\")\n",
    "firstSentence[4] = wordsList.index(\"was\")\n",
    "firstSentence[5] = wordsList.index(\"incredible\")\n",
    "firstSentence[6] = wordsList.index(\"and\")\n",
    "firstSentence[7] = wordsList.index(\"inspiring\")\n",
    "#firstSentence[8] and firstSentence[9] are going to be 0\n",
    "print(firstSentence.shape)\n",
    "print(firstSentence) #Shows the row index for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(tf.nn.embedding_lookup(wordVectors,firstSentence).eval().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive files finished\n",
      "Negative files finished\n",
      "The total number of files is 25000\n",
      "The total number of words in the files is 5844680\n",
      "The average number of words in the files is 233.7872\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "positiveFiles = ['./imdb/positiveReviews/' + f for f in listdir('./imdb/positiveReviews/') if isfile(join('./imdb/positiveReviews/', f))]\n",
    "negativeFiles = ['./imdb/negativeReviews/' + f for f in listdir('./imdb/negativeReviews/') if isfile(join('./imdb/negativeReviews/', f))]\n",
    "numWords = []\n",
    "for pf in positiveFiles:\n",
    "    with open(pf, \"r\", encoding='utf-8') as f:\n",
    "        line=f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)       \n",
    "print('Positive files finished')\n",
    "\n",
    "for nf in negativeFiles:\n",
    "    with open(nf, \"r\", encoding='utf-8') as f:\n",
    "        line=f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)  \n",
    "print('Negative files finished')\n",
    "\n",
    "numFiles = len(numWords)\n",
    "print('The total number of files is', numFiles)\n",
    "print('The total number of words in the files is', sum(numWords))\n",
    "print('The average number of words in the files is', sum(numWords)/len(numWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEKCAYAAADenhiQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLSZJ6p3JRZLUO5OLJKl3JhdJUu/+P7U0SU8tYN2+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f76ec2d24e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "myfont = fm.FontProperties(fname='/home/wumg/anaconda3/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/simhei.ttf')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.hist(numWords, 50)\n",
    "plt.xlabel('序列长度',fontproperties=myfont)\n",
    "plt.ylabel('频率',fontproperties=myfont)\n",
    "plt.axis([0, 1200, 0, 8000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I agree with the other comments. I saw this movie years ago. Christopher Plummer is hilarious as a dandy. The ribaldry is unsurpassed. If this comes out on video, I will definitely buy it.\n"
     ]
    }
   ],
   "source": [
    "maxSeqLength = 250\n",
    "fname = positiveFiles[3] #Can use any valid index (not just 3)\n",
    "with open(fname) as f:\n",
    "    for lines in f:\n",
    "        print(lines)\n",
    "        exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    41,   2137,     17, 201534,     68,   1939,     41,    822,\n",
       "           37,   1005,     82,    363,   3257,  19472,     14,  20720,\n",
       "           19,      7,  30846, 201534, 270078,     14,  60549,     83,\n",
       "           37,    934,     66,     13,    974,     41,     43,   3936,\n",
       "          987,     20,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 删除标点符号、括号、问号等，只留下字母数字字符\n",
    "import re\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())\n",
    "\n",
    "firstFile = np.zeros((maxSeqLength), dtype='int32')\n",
    "with open(fname) as f:\n",
    "    indexCounter = 0\n",
    "    line=f.readline()\n",
    "    cleanedLine = cleanSentences(line)\n",
    "    split = cleanedLine.split()\n",
    "    for word in split:\n",
    "        try:\n",
    "            firstFile[indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            firstFile[indexCounter] = 399999 #Vector for unknown words\n",
    "        indexCounter = indexCounter + 1\n",
    "firstFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = np.load('./imdb/idsMatrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        if (i % 2 == 0): \n",
    "            num = randint(1,11499)\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            num = randint(13499,24999)\n",
    "            labels.append([0,1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(11499,13499)\n",
    "        if (num <= 12499):\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            labels.append([0,1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize = 24\n",
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "iterations = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.nn.embedding_lookup(wordVectors,input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.25)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to models/pretrained_lstm.ckpt-1000\n",
      "saved to models/pretrained_lstm.ckpt-2000\n",
      "saved to models/pretrained_lstm.ckpt-3000\n",
      "saved to models/pretrained_lstm.ckpt-4000\n",
      "saved to models/pretrained_lstm.ckpt-5000\n",
      "saved to models/pretrained_lstm.ckpt-6000\n",
      "saved to models/pretrained_lstm.ckpt-7000\n",
      "saved to models/pretrained_lstm.ckpt-8000\n",
      "saved to models/pretrained_lstm.ckpt-9000\n",
      "saved to models/pretrained_lstm.ckpt-10000\n",
      "saved to models/pretrained_lstm.ckpt-11000\n",
      "saved to models/pretrained_lstm.ckpt-12000\n",
      "saved to models/pretrained_lstm.ckpt-13000\n",
      "saved to models/pretrained_lstm.ckpt-14000\n",
      "saved to models/pretrained_lstm.ckpt-15000\n",
      "saved to models/pretrained_lstm.ckpt-16000\n",
      "saved to models/pretrained_lstm.ckpt-17000\n",
      "saved to models/pretrained_lstm.ckpt-18000\n",
      "saved to models/pretrained_lstm.ckpt-19000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "with tf.device('/gpu:0'):\n",
    "    for i in range(iterations):\n",
    "       #Next Batch of reviews\n",
    "       nextBatch, nextBatchLabels = getTrainBatch();\n",
    "       sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})\n",
    " \n",
    "       #Write summary to Tensorboard\n",
    "       if (i % 50 == 0):\n",
    "           summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "           writer.add_summary(summary, i)\n",
    "\n",
    "       #Save the network every 1000 training iterations\n",
    "       if (i % 1000 == 0 and i != 0):\n",
    "           save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=i)\n",
    "           print(\"saved to %s\" % save_path)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/pretrained_lstm.ckpt-19000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('./models'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 87.5\n",
      "Accuracy for this batch: 83.3333313465\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 79.1666686535\n",
      "Accuracy for this batch: 91.6666686535\n",
      "Accuracy for this batch: 75.0\n",
      "Accuracy for this batch: 83.3333313465\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
